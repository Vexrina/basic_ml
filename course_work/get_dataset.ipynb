{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kshchavlev/Documents/itmo_projects/basic_ml/env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRC_FILE:str = \"./trc.csv\"\n",
    "TDVACH_FILE:str = \"./tdvach.csv\"\n",
    "RPT_FILE:str = \"./rpt.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pd(filePath: str)->pd.DataFrame | None:\n",
    "    if os.path.exists(filePath) and os.path.isfile(filePath):\n",
    "        return pd.read_csv(filePath, index_col=0)\n",
    "    match filePath:\n",
    "        case \"./trc.csv\":\n",
    "            df = pd.read_json(\"hf://datasets/AlexSham/Toxic_Russian_Comments/train.jsonl\", lines=True)\n",
    "        case \"./tdvach.csv\":\n",
    "            df = pd.read_csv(\"hf://datasets/marriamaslova/toxic_dvach/labeled.csv\")\n",
    "        case \"./rpt.csv\":\n",
    "            df = pd.read_csv(\"hf://datasets/s-nlp/ru_paradetox_toxicity/train.tsv\", sep=\"\\t\")\n",
    "        case _:\n",
    "            return None\n",
    "    df.to_csv(filePath)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  видимо в разных регионах называют по разному ,...      0\n",
      "1  понятно что это нарушение правил, писать капсл...      1\n",
      "2                какие классные, жизненные стихи....      0\n",
      "3                 а и правда-когда его запретили?...      0\n",
      "4  в соленой воде вирусы живут .ученые изучали со...      0\n",
      "**********\n",
      "label\n",
      "0    183316\n",
      "1     40145\n",
      "Name: count, dtype: int64\n",
      "**********\n",
      "                                                 text  label\n",
      "1   понятно что это нарушение правил, писать капсл...      1\n",
      "5   правильно! это же тихановская 26 лет растила и...      1\n",
      "13                                   на хуй, безликая      1\n",
      "16                дебилов хватает.надо было с головой      1\n",
      "30                  умник хуев. у каждого своё мнение      1\n"
     ]
    }
   ],
   "source": [
    "df1 = get_pd(TRC_FILE)\n",
    "print(df1.head())\n",
    "print(\"*\"*10)\n",
    "print(df1['label'].value_counts())\n",
    "print(\"*\"*10)\n",
    "print(df1[df1['label'] == 1].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment  toxic\n",
      "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
      "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
      "2                          Собаке - собачья смерть\\n    1.0\n",
      "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
      "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0\n",
      "**********\n",
      "toxic\n",
      "0.0    9586\n",
      "1.0    4826\n",
      "Name: count, dtype: int64\n",
      "**********\n",
      "                                             comment  toxic\n",
      "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
      "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
      "2                          Собаке - собачья смерть\\n    1.0\n",
      "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
      "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0\n"
     ]
    }
   ],
   "source": [
    "df2 = get_pd(TDVACH_FILE)\n",
    "print(df2.head())\n",
    "print(\"*\"*10)\n",
    "print(df2['toxic'].value_counts())\n",
    "print(\"*\"*10)\n",
    "print(df2[df2['toxic'] == 1].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             neutral  toxic\n",
      "0  Вот и довели себя до сахарного диабета второго...  False\n",
      "1  Мойщик машину пеной залил, а хозяин виноват? П...  False\n",
      "2                Какой совет может дать эта девушка?  False\n",
      "3                    Зачем брать топор и убивать то?  False\n",
      "4  Такой же как и Дегтярев. Другими словами оба р...  False\n",
      "**********\n",
      "toxic\n",
      "False    4848\n",
      "True     1506\n",
      "Name: count, dtype: int64\n",
      "**********\n",
      "                                              neutral  toxic\n",
      "11                     Дима! Их еще называли шестерки   True\n",
      "15  Из-за тебя глупца потом стоять, потому что ты ...   True\n",
      "19  Людей за бабки на улицы вывели чтобы гопника о...   True\n",
      "26        глупый пытается попасть в элиту этого мира?   True\n",
      "30     У тебя колорад сбился узел, помолчи пожалуйста   True\n"
     ]
    }
   ],
   "source": [
    "df3 = get_pd(RPT_FILE)\n",
    "print(df3.head())\n",
    "print(\"*\"*10)\n",
    "print(df3['toxic'].value_counts())\n",
    "print(\"*\"*10)\n",
    "print(df3[df3['toxic'] == 1].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14412 entries, 0 to 14411\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   comment  14412 non-null  object\n",
      " 1   toxic    14412 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 337.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df2['toxic'] = df2['toxic'].astype(int)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6354 entries, 0 to 6353\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   neutral  6354 non-null   object\n",
      " 1   toxic    6354 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 148.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df3['toxic'] = df3['toxic'].astype(int)\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes(\n",
    "    df1:pd.DataFrame, \n",
    "    df2:pd.DataFrame,\n",
    "    df3:pd.DataFrame,\n",
    ")-> Tuple[list[object], list[object], list[int], list[int]]:\n",
    "    x_1 = df1['text'].values\n",
    "    y_1 = df1['label'].values\n",
    "    x_1_train, x_1_test, y_1_train, y_1_test = train_test_split(x_1, y_1, test_size=0.2)\n",
    "    \n",
    "    x_2 = df2['comment'].values\n",
    "    y_2 = df2['toxic'].values\n",
    "    x_2_train, x_2_test, y_2_train, y_2_test = train_test_split(x_2, y_2, test_size=0.2)\n",
    "    \n",
    "    x_3 = df3['neutral'].values\n",
    "    y_3 = df3['toxic'].values\n",
    "    x_3_train, x_3_test, y_3_train, y_3_test = train_test_split(x_3, y_3, test_size=0.2)\n",
    "    \n",
    "    x_train = np.concatenate((x_1_train, x_2_train, x_3_train))\n",
    "    x_test = np.concatenate((x_1_test, x_2_test, x_3_test))\n",
    "    y_train = np.concatenate((y_1_train, y_2_train, y_3_train))\n",
    "    y_test = np.concatenate((y_1_test, y_2_test, y_3_test))\n",
    "    return x_train, x_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = combine_dataframes(df1, df2, df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Processing texts:   0%|          | 0/195380 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Processing texts:  92%|█████████▏| 178849/195380 [1:33:30<08:38, 31.88it/s]  \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (660) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m----> 9\u001b[0m X_embeddings \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mtext_to_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m tqdm(X_train, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing texts\u001b[39m\u001b[38;5;124m\"\u001b[39m)])\n",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m, in \u001b[0;36mtext_to_embedding\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Documents/itmo_projects/basic_ml/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/itmo_projects/basic_ml/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/itmo_projects/basic_ml/env/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:1078\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1076\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m-> 1078\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1087\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, seq_length \u001b[38;5;241m+\u001b[39m past_key_values_length), device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/itmo_projects/basic_ml/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/itmo_projects/basic_ml/env/lib/python3.13/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/itmo_projects/basic_ml/env/lib/python3.13/site-packages/transformers/models/bert/modeling_bert.py:217\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    216\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings(position_ids)\n\u001b[0;32m--> 217\u001b[0m     \u001b[43membeddings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mposition_embeddings\u001b[49m\n\u001b[1;32m    218\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)\n\u001b[1;32m    219\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(embeddings)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (660) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "model = BertModel.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "def text_to_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "X_embeddings = np.array([text_to_embedding(text) for text in tqdm(X_train, desc=\"Processing texts\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X_embeddings, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_tensor, \"X_train.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embeddings_test = np.array([text_to_embedding(text) for text in tqdm(X_test)])\n",
    "X_tensor_test = torch.tensor(X_embeddings_test, dtype=torch.float32)\n",
    "torch.save(X_tensor_test, \"X_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_tensor_test, \"X_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "после всех этих действий у нас получилися X(y)_test(train).pt файлы, хранящие в себе тензоры для обучения нейронки для распознования токсиков\n",
    "я объединил три датасета:\n",
    " - hf://datasets/AlexSham/Toxic_Russian_Comments/train.jsonl\n",
    " - hf://datasets/marriamaslova/toxic_dvach/labeled.csv\n",
    " - hf://datasets/s-nlp/ru_paradetox_toxicity/train.tsv\n",
    "предварительно взяв из каждого по 20% на тестовые выборки.\n",
    "Все признаки, т.е. сами по себе токсичные комментарии, были пропущенны через \"DeepPavlov/rubert-base-cased\", чтобы данные выглядили как цифры, а не как строки\n",
    "работа продолжится в следующем ноутбуке\n",
    "\n",
    "нормального вывода тут нет, т.к. производился эмбеддинг в гугл коллабе на гпу, для ускорения работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
